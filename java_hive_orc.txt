hive> select * from orc_tmp_table;
OK
12595   Steve   XBBLWXW DWP
12593   John    XBBLDER EDSA
12594   Broad   XBBLYRE FYG
12599   Alex    XCCFRTE EDSA
12354   Kellen  XVVBGRE DP
12987   Kiwi    XDDFRTY DWP
Time taken: 1.408 seconds, Fetched: 6 row(s)
hive> describe extended orc_tmp_table;
OK
emp_id                  int
emp_name                string
commit_id               string
app                     string

Detailed Table Information      Table(tableName:orc_tmp_table, dbName:default, owner:dshmbtm, createTime:1426600721, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:emp_id, type:int, comment:null), FieldSchema(name:emp_name, type:string, comment:null), FieldSchema(name:commit_id, type:string, comment:null), FieldSchema(name:app, type:string, comment:null)], location:hdfs://myclustertesttpc/apps/hive/warehouse/orc_tmp_table, inputFormat:org.apache.hadoop.hive.ql.io.orc.OrcInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.orc.OrcSerde, parameters:{serialization.format=,, field.delim=,}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=1, COLUMN_STATS_ACCURATE=true, transient_lastDdlTime=1426600765, numRows=6, totalSize=601, rawDataSize=1620}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)
Time taken: 0.698 seconds, Fetched: 6 row(s)


=======================================================

import java.io.IOException;
import java.security.PrivilegedExceptionAction;
import java.sql.*;

import javax.security.auth.Subject;
import javax.security.auth.callback.Callback;
import javax.security.auth.callback.CallbackHandler;
import javax.security.auth.callback.NameCallback;
import javax.security.auth.callback.PasswordCallback;
import javax.security.auth.callback.UnsupportedCallbackException;
import javax.security.auth.login.LoginContext;
import javax.security.auth.login.LoginException;
import org.apache.hadoop.hive.ql.io.orc.*;


public class Hiveorctest {
        //  JDBC credentials
        static final String JDBC_DRIVER = "org.apache.hive.jdbc.HiveDriver";
        static final String JDBC_DB_URL = "jdbc:hive2://r37an00.bnymellon.net:10000/default;principal=hive/r37an00.bnymellon.net@HADOOP-DQA-TPC01.BNYMELLON.NET;auth=kerberos;kerberosAuthType=fromSubject";
        static String QUERY = "select * from orc_tmp_table";

        static final String USER = null;
        static final String PASS = null;

    static final String KERBEROS_KRB5CONF = "./krb5.conf";
        static final String jaasConfigFilePath = "./client_jaas.conf";

        // use trusted realm user
        static final String KERBEROS_REALM = "HADOOP-DQA-TPC01.BNYMELLON.NET";
        static final String KERBEROS_KDC = "r37bn00.bnymellon.net";
        static final String KERBEROS_PRINCIPAL = "kdcadmin/admin@HADOOP-DQA-TPC01.BNYMELLON.NET";
        static final String KERBEROS_PASSWORD = "kdcadmin";

        public static class MyCallbackHandler implements CallbackHandler {

                public void handle(Callback[] callbacks)
                                throws IOException, UnsupportedCallbackException {
                        for (int i = 0; i < callbacks.length; i++) {
                                if (callbacks[i] instanceof NameCallback) {
                                        NameCallback nc = (NameCallback)callbacks[i];
                                        nc.setName(KERBEROS_PRINCIPAL);
                                } else if (callbacks[i] instanceof PasswordCallback) {
                                        PasswordCallback pc = (PasswordCallback)callbacks[i];
                                        pc.setPassword(KERBEROS_PASSWORD.toCharArray());
                                } else throw new UnsupportedCallbackException
                                (callbacks[i], "Unrecognised callback");
                        }
                }
        }

        static Subject getSubject() {
                Subject signedOnUserSubject = null;

                // create a LoginContext based on the entry in the login.conf file
                LoginContext lc;
                try {
                        lc = new LoginContext("SampleClient", new MyCallbackHandler());
                        // login (effectively populating the Subject)
                        lc.login();
                        // get the Subject that represents the signed-on user
                        signedOnUserSubject = lc.getSubject();
                } catch (LoginException e1) {
                        // TODO Auto-generated catch block
                        e1.printStackTrace();
                        System.exit(0);
                }
                return signedOnUserSubject;
        }

        static Connection getConnection( Subject signedOnUserSubject ) throws Exception{

                Connection conn = (Connection) Subject.doAs(signedOnUserSubject, new PrivilegedExceptionAction<Object>()
                                {
                        public Object run()
                        {
                                Connection con = null;
                                try {
                                        Class.forName(JDBC_DRIVER);
                                        con =  DriverManager.getConnection(JDBC_DB_URL,USER,PASS);
                                } catch (SQLException e) {
                                        e.printStackTrace();
                                } catch (ClassNotFoundException e) {
                                        e.printStackTrace();
                                }
                                return con;
                        }
                                });

                return conn;
        }
        // Print the result set.
        private static int  traverseResultSet(ResultSet rs, int max) throws SQLException
        {
                ResultSetMetaData metaData = rs.getMetaData();
                int rowIndex = 0;
                while (rs.next()) {
                        for (int i=1; i<=metaData.getColumnCount(); i++) {
                                System.out.print("  "  + rs.getString(i));
                        }
                        System.out.println();
                        rowIndex++;
                        if(max > 0 && rowIndex >= max )
                                break;
                }
                return rowIndex;
        }
        public static void main(String[] args) {
                System.setProperty("java.security.auth.login.config", jaasConfigFilePath);
                System.setProperty("java.security.krb5.conf", KERBEROS_KRB5CONF);
                System.setProperty("java.security.krb5.realm", KERBEROS_REALM );
                System.setProperty("java.security.krb5.kdc", KERBEROS_KDC);

                System.out.println("-- Test started ---");
                Subject sub = getSubject();

                Connection conn = null;
                try {
                        conn = getConnection(sub);
                        Statement stmt = conn.createStatement() ;
                        ResultSet rs = stmt.executeQuery( QUERY );
                        traverseResultSet(rs,5);

                } catch (Exception e){
                        e.printStackTrace();
                } finally {
                        try { if (conn != null) conn.close(); } catch(Exception e) { e.printStackTrace();}
                }

                System.out.println("Test ended  ");
        }
}

=============================================================================================
export variables 
----------------
export JAVA_HOME=/usr/jdk/jdk1.6.0_31
export HADOOP_HOME=/usr/lib/hadoop
export HIVE_HOME=/usr/lib/hive
export HADOOP_CLASSPATH=
export CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/db/lib/*:$JAVA_HOME/jre/lib/rt.jar:/usr/lib/hive/lib/hive-metastore-0.13.0.2.1.2.0-402.jar:$HIVE_HOME/lib/*:$HADOOP_HOME/*:$HADOOP_HOME/lib/*:$HADOOP_HOME/hadoop-common-2.4.0.2.1.2.0-402.jar:$HADOOP_HOME/lib/commons-cli-1.2.jar:/usr/lib/hive/lib/hive-jdbc-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/hadoop-annotations-2.4.0.2.1.2.0-402.jar:/usr/lib/hive/lib/hive-common-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/lib/mysql-connector-java.jar:/usr/lib/hive/lib/hive-metastore-0.13.0.2.1.2.0-402.jar:/usr/lib/hive/lib/hive-exec-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/client/httpclient-4.2.5.jar:/usr/lib/hive/lib/hive-service-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hive/lib/libthrift-0.9.0.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hive/lib/libfb303-0.9.0.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/users/home/xbblkc5/New_folder/lib/slf4j-simple-1.6.6.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/users/home/xbblkc5/New_folder/lib/geronimo-j2ee-management_1.1_spec-1.0.1.jar:/users/home/xbblkc5/New_folder/lib/jsr305-1.3.9.jar:/users/home/xbblkc5/New_folder/lib/hadoop-auth-2.4.0.2.1.2.0-402.jar:/users/home/xbblkc5/New_folder/lib/activemq-client-5.8.0.jar:/users/home/xbblkc5/New_folder/lib/xml-apis-1.4.01.jar:/users/home/xbblkc5/New_folder/lib/hawtbuf-1.9.jar:/users/home/xbblkc5/New_folder/lib/commons-codec-1.4.jar:/users/home/xbblkc5/New_folder/lib/json-simple-1.1.jar:/users/home/xbblkc5/New_folder/lib/geronimo-jms_1.1_spec-1.1.1.jar:/users/home/xbblkc5/New_folder/lib/jackson-core-asl-1.8.8.jar:/users/home/xbblkc5/New_folder/lib/oozie-client-4.0.0.2.1.2.0-402.jar:/users/home/xbblkc5/New_folder/lib/jackson-mapper-asl-1.8.8.jar:/users/home/xbblkc5/New_folder/lib/guava-11.0.2.jar:/users/home/xbblkc5/New_folder/lib/xercesImpl-2.10.0.jar:/usr/lib/hive/lib/commons-httpclient-3.0.1.jar:/usr/lib/hadoop/client/hadoop-mapreduce-client-app-2.4.0.2.1.2.0-402.jar

export PATH=$PATH:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/jdk/jdk1.6.0_31/bin:/usr/lib/hadoop/bin:/usr/lib/hive/bin

javac Hiveorctest.java
============================================================
#!/bin/bash
HADOOP_HOME=/usr/lib/hadoop
HIVE_HOME=/usr/lib/hive
 
echo -e '1\x01foo' > /tmp/a.txt
echo -e '2\x01bar' >> /tmp/a.txt
 
HADOOP_CORE=$(ls $HADOOP_HOME/hadoop-core*.jar)
CLASSPATH=.:$HIVE_HOME/conf:$(hadoop classpath)
 
for i in ${HIVE_HOME}/lib/*.jar ; do
    CLASSPATH=$CLASSPATH:$i
done
 
java -cp $CLASSPATH Hiveorctest



