12595   Steve   XBBLWXW DWP
12593   John    XBBLDER EDSA
12594   Broad   XBBLYRE FYG
12599   Alex    XCCFRTE EDSA
12354   Kellen  XVVBGRE DP
12987   Kiwi    XDDFRTY DWP
 
CREATE TABLE avro_tmp_table
ROW FORMAT SERDE
'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
STORED AS INPUTFORMAT
'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
OUTPUTFORMAT
'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
TBLPROPERTIES ( 'avro.schema.literal'='{
"namespace": "testns", "name": "test_schema", "type": "record",
"fields": [ {"name": "emp_id","type": "int"},{"name": "name","type": "string"},{"name": "com_id","type": "string"},{"name": "application","type": "string"}] }');


	
hive> describe extended avro_tmp_table;
OK
emp_id                  int                     from deserializer
name                    string                  from deserializer
com_id                  string                  from deserializer
application             string                  from deserializer

Detailed Table Information      Table(tableName:avro_tmp_table, dbName:default, owner:dshmbtm, createTime:1427094865, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[], location:hdfs://myclustertesttpc/apps/hive/warehouse/avro_tmp_table, inputFormat:org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.avro.AvroSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=1, avro.schema.literal={
"namespace": "testns", "name": "test_schema", "type": "record",
"fields": [ {"name": "emp_id","type": "int"},{"name": "name","type": "string"},{"name": "com_id","type": "string"},{"name": "application","type": "string"}] }, COLUMN_STATS_ACCURATE=true, transient_lastDdlTime=1427094893, numRows=6, totalSize=386, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)
Time taken: 0.735 seconds, Fetched: 8 row(s)


select * from temp_tbl1;

FROM temp_tbl1 t
INSERT INTO TABLE avro_tmp_table 
SELECT t.emp_id, t.emp_name, t.commit_id, t.application;

hive> select * from default.avro_tmp_table;
OK
12595   Steve   XBBLWXW DWP
12593   John    XBBLDER EDSA
12594   Broad   XBBLYRE FYG
12599   Alex    XCCFRTE EDSA
12354   Kellen  XVVBGRE DP
12987   Kiwi    XDDFRTY DWP
Time taken: 0.573 seconds, Fetched: 6 row(s)
------------------------------------------
CREATE TABLE avro_tmp_table_json
ROW FORMAT SERDE
'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
TBLPROPERTIES ( 'avro.schema.literal'='{
"namespace": "testns", "name": "test_schema", "type": "record",
"fields": [ {"name": "emp_id","type": "int"},{"name": "name","type": "string"},{"name": "com_id","type": "string"},{"name": "application","type": "string"}] }');



FROM temp_tbl1 t
INSERT INTO TABLE avro_tmp_table_json 
SELECT t.emp_id, t.emp_name, t.commit_id, t.application;
-----------------------------------------------------------------
CREATE TABLE avro_tmp_table_text
ROW FORMAT SERDE
'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
STORED AS 
INPUTFORMAT
'org.apache.hadoop.io.Text'
OUTPUTFORMAT
'org.apache.hadoop.io.Text'
TBLPROPERTIES ( 'avro.schema.literal'='{
"namespace": "testns", "name": "test_schema", "type": "record",
"fields": [ {"name": "emp_id","type": "int"},{"name": "name","type": "string"},{"name": "com_id","type": "string"},{"name": "application","type": "string"}] }');





FROM temp_tbl1 t
INSERT INTO TABLE avro_tmp_table_text
SELECT t.emp_id, t.emp_name, t.commit_id, t.application;

--------------------------------------------------------------------------------
//

REGISTER /usr/lib/pig/lib/avro-mapred-1.7.4.jar
REGISTER /usr/lib/pig/lib/piggybank.jar
REGISTER /usr/lib/pig/lib/json-simple-1.1.jar
REGISTER /tmp/ToJson.jar
data2 = LOAD '/apps/hive/warehouse/avro_tmp_table/000000_0' USING AvroStorage();
data = LIMIT data2 1;	
son_test = foreach data generate name, myudf.ToJson(emp_id) as bag_json;


data2 = LOAD '/apps/hive/warehouse/avro_tmp_table/000000_0' USING AvroStorage('{
"namespace": "testns", "name": "test_schema", "type": "record",
"fields": [ {"name": "emp_id","type": "int"},{"name": "name","type": "string"},{"name": "com_id","type": "string"},{"name": "application","type": "string"}] }');

store data2 into '/tmp/json' using JsonStorage();


pig -Dpig.additional.jars=/users/home/dshmbtm/pig_jar/ToJson.jar

REGISTER /tmp/UPPER.jar
REGISTER /usr/lib/pig/lib/avro-mapred-1.7.4.jar
data2 = LOAD '/apps/hive/warehouse/avro_tmp_table/000000_0' USING AvroStorage();
up = foreach data2 generate UPPER(name);
-----------------------------------
Vealaikku aagala ****
CREATE EXTERNAL TABLE Json_test1 (
 emp_id STRING,
 name STRING,
 com_id STRING,
 application STRING
)
ROW FORMAT SERDE "org.apache.hadoop.hive.contrib.serde2.JsonSerde"

load data inpath '/apps/hive/warehouse/avro_tmp_table/000000_0' into table Json_test1
=============================
describe extended  avro_tmp_table_json
Detailed Table Information      Table(tableName:avro_tmp_table_json, dbName:default, owner:dshmhtm, createTime:1430997333, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[], location:hdfs://myclustertesttpc/apps/hive/warehouse/avro_tmp_table_json, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.avro.AvroSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{avro.schema.literal={
"namespace": "testns", "name": "test_schema", "type": "record",
"fields": [ {"name": "emp_id","type": "int"},{"name": "name","type": "string"},{"name": "com_id","type": "string"},{"name": "application","type": "string"}] }, transient_lastDdlTime=1430997333}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE)
Time taken: 0.442 seconds, Fetched: 8 row(s)




=======================================================

import java.io.IOException;
import java.security.PrivilegedExceptionAction;
import java.sql.*;

import javax.security.auth.Subject;
import javax.security.auth.callback.Callback;
import javax.security.auth.callback.CallbackHandler;
import javax.security.auth.callback.NameCallback;
import javax.security.auth.callback.PasswordCallback;
import javax.security.auth.callback.UnsupportedCallbackException;
import javax.security.auth.login.LoginContext;
import javax.security.auth.login.LoginException;
import org.apache.hadoop.hive.ql.io.orc.*;


public class Hiveavrotest {
        //  JDBC credentials
        static final String JDBC_DRIVER = "org.apache.hive.jdbc.HiveDriver";
        static final String JDBC_DB_URL = "jdbc:hive2://r37an00.bnymellon.net:10000/default;principal=hive/r37an00.bnymellon.net@HADOOP-DQA-TPC01.BNYMELLON.NET;auth=kerberos;kerberosAuthType=fromSubject";
        static String QUERY = "select * from avro_tmp_table";

        static final String USER = null;
        static final String PASS = null;

    static final String KERBEROS_KRB5CONF = "./krb5.conf";
        static final String jaasConfigFilePath = "./client_jaas.conf";

        // use trusted realm user
        static final String KERBEROS_REALM = "HADOOP-DQA-TPC01.BNYMELLON.NET";
        static final String KERBEROS_KDC = "r37bn00.bnymellon.net";
        static final String KERBEROS_PRINCIPAL = "kdcadmin/admin@HADOOP-DQA-TPC01.BNYMELLON.NET";
        static final String KERBEROS_PASSWORD = "kdcadmin";

        public static class MyCallbackHandler implements CallbackHandler {

                public void handle(Callback[] callbacks)
                                throws IOException, UnsupportedCallbackException {
                        for (int i = 0; i < callbacks.length; i++) {
                                if (callbacks[i] instanceof NameCallback) {
                                        NameCallback nc = (NameCallback)callbacks[i];
                                        nc.setName(KERBEROS_PRINCIPAL);
                                } else if (callbacks[i] instanceof PasswordCallback) {
                                        PasswordCallback pc = (PasswordCallback)callbacks[i];
                                        pc.setPassword(KERBEROS_PASSWORD.toCharArray());
                                } else throw new UnsupportedCallbackException
                                (callbacks[i], "Unrecognised callback");
                        }
                }
        }

        static Subject getSubject() {
                Subject signedOnUserSubject = null;

                // create a LoginContext based on the entry in the login.conf file
                LoginContext lc;
                try {
                        lc = new LoginContext("SampleClient", new MyCallbackHandler());
                        // login (effectively populating the Subject)
                        lc.login();
                        // get the Subject that represents the signed-on user
                        signedOnUserSubject = lc.getSubject();
                } catch (LoginException e1) {
                        // TODO Auto-generated catch block
                        e1.printStackTrace();
                        System.exit(0);
                }
                return signedOnUserSubject;
        }

        static Connection getConnection( Subject signedOnUserSubject ) throws Exception{

                Connection conn = (Connection) Subject.doAs(signedOnUserSubject, new PrivilegedExceptionAction<Object>()
                                {
                        public Object run()
                        {
                                Connection con = null;
                                try {
                                        Class.forName(JDBC_DRIVER);
                                        con =  DriverManager.getConnection(JDBC_DB_URL,USER,PASS);
                                } catch (SQLException e) {
                                        e.printStackTrace();
                                } catch (ClassNotFoundException e) {
                                        e.printStackTrace();
                                }
                                return con;
                        }
                                });

                return conn;
        }
        // Print the result set.
        private static int  traverseResultSet(ResultSet rs, int max) throws SQLException
        {
                ResultSetMetaData metaData = rs.getMetaData();
                int rowIndex = 0;
                while (rs.next()) {
                        for (int i=1; i<=metaData.getColumnCount(); i++) {
                                System.out.print("  "  + rs.getString(i));
                        }
                        System.out.println();
                        rowIndex++;
                        if(max > 0 && rowIndex >= max )
                                break;
                }
                return rowIndex;
        }
        public static void main(String[] args) {
                System.setProperty("java.security.auth.login.config", jaasConfigFilePath);
                System.setProperty("java.security.krb5.conf", KERBEROS_KRB5CONF);
                System.setProperty("java.security.krb5.realm", KERBEROS_REALM );
                System.setProperty("java.security.krb5.kdc", KERBEROS_KDC);

                System.out.println("-- Test started ---");
                Subject sub = getSubject();

                Connection conn = null;
                try {
                        conn = getConnection(sub);
                        Statement stmt = conn.createStatement() ;
                        ResultSet rs = stmt.executeQuery( QUERY );
                        traverseResultSet(rs,5);

                } catch (Exception e){
                        e.printStackTrace();
                } finally {
                        try { if (conn != null) conn.close(); } catch(Exception e) { e.printStackTrace();}
                }

                System.out.println("Test ended  ");
        }
}

=============================================================================================
export variables 
----------------
export JAVA_HOME=/usr/jdk/jdk1.6.0_31
export HADOOP_HOME=/usr/lib/hadoop
export HIVE_HOME=/usr/lib/hive
export HADOOP_CLASSPATH=
export CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/db/lib/*:$JAVA_HOME/jre/lib/rt.jar:/usr/lib/hive/lib/hive-metastore-0.13.0.2.1.2.0-402.jar:$HIVE_HOME/lib/*:$HADOOP_HOME/*:$HADOOP_HOME/lib/*:$HADOOP_HOME/hadoop-common-2.4.0.2.1.2.0-402.jar:$HADOOP_HOME/lib/commons-cli-1.2.jar:/usr/lib/hive/lib/hive-jdbc-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/hadoop-annotations-2.4.0.2.1.2.0-402.jar:/usr/lib/hive/lib/hive-common-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/lib/mysql-connector-java.jar:/usr/lib/hive/lib/hive-metastore-0.13.0.2.1.2.0-402.jar:/usr/lib/hive/lib/hive-exec-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/client/httpclient-4.2.5.jar:/usr/lib/hive/lib/hive-service-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hive/lib/libthrift-0.9.0.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hive/lib/libfb303-0.9.0.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/users/home/xbblkc5/New_folder/lib/slf4j-simple-1.6.6.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/users/home/xbblkc5/New_folder/lib/geronimo-j2ee-management_1.1_spec-1.0.1.jar:/users/home/xbblkc5/New_folder/lib/jsr305-1.3.9.jar:/users/home/xbblkc5/New_folder/lib/hadoop-auth-2.4.0.2.1.2.0-402.jar:/users/home/xbblkc5/New_folder/lib/activemq-client-5.8.0.jar:/users/home/xbblkc5/New_folder/lib/xml-apis-1.4.01.jar:/users/home/xbblkc5/New_folder/lib/hawtbuf-1.9.jar:/users/home/xbblkc5/New_folder/lib/commons-codec-1.4.jar:/users/home/xbblkc5/New_folder/lib/json-simple-1.1.jar:/users/home/xbblkc5/New_folder/lib/geronimo-jms_1.1_spec-1.1.1.jar:/users/home/xbblkc5/New_folder/lib/jackson-core-asl-1.8.8.jar:/users/home/xbblkc5/New_folder/lib/oozie-client-4.0.0.2.1.2.0-402.jar:/users/home/xbblkc5/New_folder/lib/jackson-mapper-asl-1.8.8.jar:/users/home/xbblkc5/New_folder/lib/guava-11.0.2.jar:/users/home/xbblkc5/New_folder/lib/xercesImpl-2.10.0.jar:/usr/lib/hive/lib/commons-httpclient-3.0.1.jar:/usr/lib/hadoop/client/hadoop-mapreduce-client-app-2.4.0.2.1.2.0-402.jar
*/
export PATH=$PATH:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/jdk/jdk1.6.0_31/bin:/usr/lib/hadoop/bin:/usr/lib/hive/bin

javac Hiveavrotest.java
============================================================
#!/bin/bash
HADOOP_HOME=/usr/lib/hadoop
HIVE_HOME=/usr/lib/hive
 
echo -e '1\x01foo' > /tmp/a.txt
echo -e '2\x01bar' >> /tmp/a.txt
 
HADOOP_CORE=$(ls $HADOOP_HOME/hadoop-core*.jar)
CLASSPATH=.:$HIVE_HOME/conf:$(hadoop classpath)
 
for i in ${HIVE_HOME}/lib/*.jar ; do
    CLASSPATH=$CLASSPATH:$i
done
 
java -cp $CLASSPATH Hiveorctest

//java -cp $CLASSPATH HiveJdbcClient

====================================================================*/
Debug is  true storeKey false useTicketCache false useKeyTab false doNotPrompt false ticketCache is null isInitiator true KeyTab is null refreshKrb5Config is false principal is null tryFirstPass is false useFirstPass is false storePass is false clearPass is false
                [Krb5LoginModule] user entered username: kdcadmin/admin@HADOOP-DQA-TPC01.BNYMELLON.NET

Acquire TGT using AS Exchange
principal is kdcadmin/admin@HADOOP-DQA-TPC01.BNYMELLON.NET
EncryptionKey: keyType=3 keyBytes (hex dump)=0000: 9D 91 58 26 38 5E 85 20
EncryptionKey: keyType=1 keyBytes (hex dump)=0000: 9D 91 58 26 38 5E 85 20
EncryptionKey: keyType=23 keyBytes (hex dump)=0000: 91 09 96 4F 8E 02 76 DB   55 F8 13 09 A6 CD BD 2C  ...O..v.U......,

EncryptionKey: keyType=16 keyBytes (hex dump)=0000: B9 EF AD 29 BC A1 08 A2   4C 19 6D 6D FD C2 67 19  ...)....L.mm..g.
0010: 79 46 AE 94 62 89 23 C1
EncryptionKey: keyType=17 keyBytes (hex dump)=0000: CA 2E 6B B6 D2 36 C1 6D   00 48 AF 69 68 E5 EB E2  ..k..6.m.H.ih...

EncryptionKey: keyType=18 keyBytes (hex dump)=0000: 98 FF 5E 6F 46 70 59 64   01 83 45 6D 0A 93 41 C7  ..^oFpYd..Em..A.
0010: B2 A9 35 AF 58 47 E1 A6   F6 E3 D5 38 E8 79 27 CA  ..5.XG.....8.y'.

Commit Succeeded

  12595  Steve  XBBLWXW  DWP
  12593  John  XBBLDER  EDSA
  12594  Broad  XBBLYRE  FYG
  12599  Alex  XCCFRTE  EDSA
  12354  Kellen  XVVBGRE  DP
Test ended

