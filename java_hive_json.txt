Loading Json Data to hive
--------------------------/apps/hive/warehouse/json_test
CREATE EXTERNAL TABLE Json_test (
 id1 STRING,
 id2 STRING,
 type STRING
)
ROW FORMAT SERDE "org.apache.hadoop.hive.contrib.serde2.JsonSerde"
WITH SERDEPROPERTIES (
 "id1"="id1",
 "id2"="id2",
 "type"="type"
)

load data inpath '/tmp/test.json' into table Json_test;

hive> describe extended Json_test;
OK
id1                     string                  from deserializer
id2                     string                  from deserializer
type                    string                  from deserializer

Detailed Table Information      Table(tableName:json_test, dbName:default, owner:dshmbtm, createTime:1426848806, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:id1, type:string, comment:null), FieldSchema(name:id2, type:string, comment:null), FieldSchema(name:type, type:string, comment:null)], location:hdfs://myclustertesttpc/apps/hive/warehouse/json_test, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.contrib.serde2.JsonSerde, parameters:{id2=id2, id1=id1, serialization.format=1, type=type}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{numFiles=1, EXTERNAL=TRUE, COLUMN_STATS_ACCURATE=true, transient_lastDdlTime=1426848877, totalSize=86, numRows=0, rawDataSize=0}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE)
Time taken: 0.684 seconds, Fetched: 5 row(s)
=============================================================

import java.io.IOException;
import java.security.PrivilegedExceptionAction;
import java.sql.*;

import javax.security.auth.Subject;
import javax.security.auth.callback.Callback;
import javax.security.auth.callback.CallbackHandler;
import javax.security.auth.callback.NameCallback;
import javax.security.auth.callback.PasswordCallback;
import javax.security.auth.callback.UnsupportedCallbackException;
import javax.security.auth.login.LoginContext;
import javax.security.auth.login.LoginException;
import org.apache.hadoop.hive.ql.io.orc.*;


public class HiveJsontest {
        //  JDBC credentials
        static final String JDBC_DRIVER = "org.apache.hive.jdbc.HiveDriver";
        static final String JDBC_DB_URL = "jdbc:hive2://r37an00.bnymellon.net:10000/default;principal=hive/r37an00.bnymellon.net@HADOOP-DQA-TPC01.BNYMELLON.NET;auth=kerberos;kerberosAuthType=fromSubject";
        static String QUERY = "select * from Json_test";

        static final String USER = null;
        static final String PASS = null;

    static final String KERBEROS_KRB5CONF = "./krb5.conf";
        static final String jaasConfigFilePath = "./client_jaas.conf";

        // use trusted realm user
        static final String KERBEROS_REALM = "HADOOP-DQA-TPC01.BNYMELLON.NET";
        static final String KERBEROS_KDC = "r37bn00.bnymellon.net";
        static final String KERBEROS_PRINCIPAL = "kdcadmin/admin@HADOOP-DQA-TPC01.BNYMELLON.NET";
        static final String KERBEROS_PASSWORD = "kdcadmin";

        public static class MyCallbackHandler implements CallbackHandler {

                public void handle(Callback[] callbacks)
                                throws IOException, UnsupportedCallbackException {
                        for (int i = 0; i < callbacks.length; i++) {
                                if (callbacks[i] instanceof NameCallback) {
                                        NameCallback nc = (NameCallback)callbacks[i];
                                        nc.setName(KERBEROS_PRINCIPAL);
                                } else if (callbacks[i] instanceof PasswordCallback) {
                                        PasswordCallback pc = (PasswordCallback)callbacks[i];
                                        pc.setPassword(KERBEROS_PASSWORD.toCharArray());
                                } else throw new UnsupportedCallbackException
                                (callbacks[i], "Unrecognised callback");
                        }
                }
        }

        static Subject getSubject() {
                Subject signedOnUserSubject = null;

                // create a LoginContext based on the entry in the login.conf file
                LoginContext lc;
                try {
                        lc = new LoginContext("SampleClient", new MyCallbackHandler());
                        // login (effectively populating the Subject)
                        lc.login();
                        // get the Subject that represents the signed-on user
                        signedOnUserSubject = lc.getSubject();
                } catch (LoginException e1) {
                        // TODO Auto-generated catch block
                        e1.printStackTrace();
                        System.exit(0);
                }
                return signedOnUserSubject;
        }

        static Connection getConnection( Subject signedOnUserSubject ) throws Exception{

                Connection conn = (Connection) Subject.doAs(signedOnUserSubject, new PrivilegedExceptionAction<Object>()
                                {
                        public Object run()
                        {
                                Connection con = null;
                                try {
                                        Class.forName(JDBC_DRIVER);
                                        con =  DriverManager.getConnection(JDBC_DB_URL,USER,PASS);
                                } catch (SQLException e) {
                                        e.printStackTrace();
                                } catch (ClassNotFoundException e) {
                                        e.printStackTrace();
                                }
                                return con;
                        }
                                });

                return conn;
        }
        // Print the result set.
        private static int  traverseResultSet(ResultSet rs, int max) throws SQLException
        {
                ResultSetMetaData metaData = rs.getMetaData();
                int rowIndex = 0;
                while (rs.next()) {
                        for (int i=1; i<=metaData.getColumnCount(); i++) {
                                System.out.print("  "  + rs.getString(i));
                        }
                        System.out.println();
                        rowIndex++;
                        if(max > 0 && rowIndex >= max )
                                break;
                }
                return rowIndex;
        }
        public static void main(String[] args) {
                System.setProperty("java.security.auth.login.config", jaasConfigFilePath);
                System.setProperty("java.security.krb5.conf", KERBEROS_KRB5CONF);
                System.setProperty("java.security.krb5.realm", KERBEROS_REALM );
                System.setProperty("java.security.krb5.kdc", KERBEROS_KDC);

                System.out.println("-- Test started ---");
                Subject sub = getSubject();

                Connection conn = null;
                try {
                        conn = getConnection(sub);
                        Statement stmt = conn.createStatement() ;
                        ResultSet rs = stmt.executeQuery( QUERY );
                        traverseResultSet(rs,5);

                } catch (Exception e){
                        e.printStackTrace();
                } finally {
                        try { if (conn != null) conn.close(); } catch(Exception e) { e.printStackTrace();}
                }

                System.out.println("Test ended  ");
        }
}

================================================================

export JAVA_HOME=/usr/jdk/jdk1.6.0_31
export HADOOP_HOME=/usr/lib/hadoop
export HIVE_HOME=/usr/lib/hive
export HADOOP_CLASSPATH=/usr/lib/hbase/lib/hbase-common-0.98.0.2.1.2.0-402-hadoop2.jar:/usr/lib/hbase/lib/hbase-common-0.98.0.2.1.2.0-402-hadoop2-tests.jar:/etc/hbase/conf:/usr/lib/hbase/lib/zookeeper.jar:/usr/lib/hive/lib/*.jar:/usr/lib/hbase/:/usr/lib/hive/lib/hive-json-serde-0.2.jar:/usr/lib/hive/lib/hive-serde-0.13.0.2.1.2.0-402.jar:/usr/lib/hive/lib/hive-serde.jar:/usr/lib/hive/lib/json-serde-1.1.4-jar-with-dependencies.jar
export CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/db/lib/*:$JAVA_HOME/jre/lib/rt.jar:/usr/lib/hive/lib/hive-metastore-0.13.0.2.1.2.0-402.jar:$HIVE_HOME/lib/*:$HADOOP_HOME/*:$HADOOP_HOME/lib/*:$HADOOP_HOME/hadoop-common-2.4.0.2.1.2.0-402.jar:$HADOOP_HOME/lib/commons-cli-1.2.jar:/usr/lib/hive/lib/hive-jdbc-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/hadoop-annotations-2.4.0.2.1.2.0-402.jar:/usr/lib/hive/lib/hive-common-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/lib/mysql-connector-java.jar:/usr/lib/hive/lib/hive-metastore-0.13.0.2.1.2.0-402.jar:/usr/lib/hive/lib/hive-exec-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/client/httpclient-4.2.5.jar:/usr/lib/hive/lib/hive-service-0.13.0.2.1.2.0-402.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hive/lib/libthrift-0.9.0.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hive/lib/libfb303-0.9.0.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/users/home/xbblkc5/New_folder/lib/slf4j-simple-1.6.6.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/users/home/xbblkc5/New_folder/lib/geronimo-j2ee-management_1.1_spec-1.0.1.jar:/users/home/xbblkc5/New_folder/lib/jsr305-1.3.9.jar:/users/home/xbblkc5/New_folder/lib/hadoop-auth-2.4.0.2.1.2.0-402.jar:/users/home/xbblkc5/New_folder/lib/activemq-client-5.8.0.jar:/users/home/xbblkc5/New_folder/lib/xml-apis-1.4.01.jar:/users/home/xbblkc5/New_folder/lib/hawtbuf-1.9.jar:/users/home/xbblkc5/New_folder/lib/commons-codec-1.4.jar:/users/home/xbblkc5/New_folder/lib/json-simple-1.1.jar:/users/home/xbblkc5/New_folder/lib/geronimo-jms_1.1_spec-1.1.1.jar:/users/home/xbblkc5/New_folder/lib/jackson-core-asl-1.8.8.jar:/users/home/xbblkc5/New_folder/lib/oozie-client-4.0.0.2.1.2.0-402.jar:/users/home/xbblkc5/New_folder/lib/jackson-mapper-asl-1.8.8.jar:/users/home/xbblkc5/New_folder/lib/guava-11.0.2.jar:/users/home/xbblkc5/New_folder/lib/xercesImpl-2.10.0.jar:/usr/lib/hive/lib/commons-httpclient-3.0.1.jar:/usr/lib/hadoop/client/hadoop-mapreduce-client-app-2.4.0.2.1.2.0-402.jar:/usr/lib/hive/lib/hive-json-serde-0.2.jar:/usr/lib/hive/lib/hive-serde-0.13.0.2.1.2.0-402.jar:/usr/lib/hive/lib/hive-serde.jar:/usr/lib/hive/lib/json-serde-1.1.4-jar-with-dependencies.jar

export PATH=$PATH:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/jdk/jdk1.6.0_31/bin:/usr/lib/hadoop/bin:/usr/lib/hive/bin



=========================================================

java.sql.SQLException: Error while compiling statement: FAILED: RuntimeException MetaException(message:java.lang.ClassNotFoundException Class org.apache.hadoop.hive.contrib.serde2.JsonSerde not found)
        at org.apache.hive.jdbc.Utils.verifySuccess(Utils.java:121)
        at org.apache.hive.jdbc.Utils.verifySuccessWithInfo(Utils.java:109)
        at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:231)
        at org.apache.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:355)
        at HiveJsontest.main(HiveJsontest.java:121)

